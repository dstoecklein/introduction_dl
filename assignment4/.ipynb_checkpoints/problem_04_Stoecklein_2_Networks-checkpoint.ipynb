{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d04d7a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "488b0d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec6cc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../datasets/MixedMNIST/'\n",
    "images_dir = '../datasets/MixedMNIST/images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce81c8b",
   "metadata": {},
   "source": [
    "# Mnist Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15753cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = ImageFolder(\n",
    "    images_dir + 'train', \n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor()\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61570228",
   "metadata": {},
   "source": [
    "# Mnist Train Datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd2c6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Train_Datasource(Dataset):\n",
    "    def __init__(self, csv_file, img_folder, transform=None):\n",
    "        self.csv = pd.read_csv(csv_file)\n",
    "        self.image_id = self.csv.id\n",
    "  \n",
    "        self.image_names = self.csv.image\n",
    "        self.classification = self.csv.classification\n",
    "        self.labels = self.csv.datasource\n",
    "\n",
    "        self.img_folder = img_folder\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.img_folder + \"/\" + str(self.classification[index]), self.csv.iloc[index, 1]) # 'image' column\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = self.labels[index]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18866491",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_datasource = MNIST_Train_Datasource(\n",
    "    csv_file = root_dir + 'train_processed.csv', \n",
    "    img_folder = images_dir + 'train',\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Grayscale(num_output_channels = 1),\n",
    "            transforms.ToTensor()\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860658b8",
   "metadata": {},
   "source": [
    "# Mnist Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bb6c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Test(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.image_id = self.annotations.id\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 1]) # 'image' column\n",
    "        image = Image.open(img_path)\n",
    "        image_id = self.image_id[index]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7ee2711",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = MNIST_Test(\n",
    "    csv_file = root_dir + 'test.csv', \n",
    "    root_dir = images_dir + 'test', \n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Grayscale(num_output_channels = 1),\n",
    "            transforms.ToTensor()\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a1fc7b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "933bdfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, input_channels, fc_output1, fc_output2):\n",
    "        super(Residual, self).__init__()\n",
    "        self.lin1 = nn.Linear(input_channels, fc_output1)\n",
    "        self.lin2 = nn.Linear(fc_output1, fc_output2)\n",
    "        self.lin3 = nn.Linear(input_channels, fc_output2)\n",
    "        \n",
    "\n",
    "        self.rel1 = nn.ReLU()\n",
    "        self.rel2 = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(input_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(fc_output1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = self.bn1(X)\n",
    "        Y = self.rel1(Y)\n",
    "        Y = F.dropout(Y, p=0.5)\n",
    "        Y = self.lin1(Y)\n",
    "        Y = self.bn2(Y)\n",
    "        Y = self.rel2(Y)\n",
    "        Y = self.lin2(Y)\n",
    "        Y += self.lin3(X)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "667ebf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_features, fc_output1, fc_output2, outputs):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = nn.Sequential(nn.Flatten(), \n",
    "                          nn.Linear(input_features, 256),\n",
    "                          Residual(256, fc_output1, fc_output2),\n",
    "                          nn.BatchNorm1d(fc_output2),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(fc_output2, 64),\n",
    "                          Residual(64, fc_output1, fc_output2),\n",
    "                          nn.BatchNorm1d(fc_output2),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(fc_output2, outputs),\n",
    "                          )\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = self.net(X)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe8c93",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b826e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_accuracy(model, data_loader):\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    num_examples = 0\n",
    "    \n",
    "    # turn on eval mode if model Inherits from nn.Module\n",
    "    if isinstance(model, nn.Module):\n",
    "        model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_index, (features, labels) in enumerate(data_loader):\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(features)\n",
    "            _, predictions = torch.max(logits, dim=1) # single class with highest probability. simply retain indices\n",
    "            \n",
    "            num_examples += labels.size(0)\n",
    "\n",
    "            correct += (predictions == labels).sum().float()\n",
    "            wrong += (predictions != labels).sum().float()\n",
    "            \n",
    "        accuracy = correct / num_examples * 100      \n",
    "        \n",
    "    return correct, wrong, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb32e29",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be6fae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader, epochs, learning_rate, loss_func=nn.CrossEntropyLoss(), opt_func=torch.optim.SGD):\n",
    "    \n",
    "    optimizer = opt_func(model.parameters(), learning_rate) # objective function\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    start = time.time() # measure time\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model = model.train()\n",
    "              \n",
    "        for batch_index, (features, labels) in enumerate(train_loader):\n",
    "            \n",
    "            # gpu usage if possible\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 1. forward\n",
    "            logits = model(features)\n",
    "\n",
    "            # 2. compute objective function (softmax, cross entropy)\n",
    "            cost = loss_func(logits, labels)\n",
    "            \n",
    "            # 3. cleaning gradients\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            # 4. accumulate partial derivatives\n",
    "            cost.backward() \n",
    "\n",
    "            # 5. step in the opposite direction of the gradient\n",
    "            optimizer.step() \n",
    "            \n",
    "            if not batch_index % 250:\n",
    "                print ('Epoch: {}/{} | Batch {}/{} | Cost: {:.4f}'.format(\n",
    "                    epoch+1,\n",
    "                    epochs,\n",
    "                    batch_index,\n",
    "                    len(train_loader),\n",
    "                    cost\n",
    "                ))\n",
    "        \n",
    "        correct, wrong, accuracy = comp_accuracy(model, train_loader)\n",
    "        print ('Training: Correct[{:.0f}] | Wrong[{:.0f}] | Accuracy[{:.2f}%]'.format(\n",
    "            correct,\n",
    "            wrong,\n",
    "            accuracy\n",
    "        ), '\\n')\n",
    "         \n",
    "    end = time.time()\n",
    "    print('Training time: {:.2f} seconds on {}'.format(\n",
    "        end - start, \n",
    "        device\n",
    "    ))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cae51a1",
   "metadata": {},
   "source": [
    "# Datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b33feb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_datasource = MLP(784, 200, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7ff3088",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "epochs = 5\n",
    "learning_rate = 0.05\n",
    "\n",
    "train_loader_datasource = DataLoader(mnist_train_datasource, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80bc3526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5 | Batch 0/4800 | Cost: 2.2643\n",
      "Epoch: 1/5 | Batch 250/4800 | Cost: 0.0099\n",
      "Epoch: 1/5 | Batch 500/4800 | Cost: 0.0130\n",
      "Epoch: 1/5 | Batch 750/4800 | Cost: 0.0025\n",
      "Epoch: 1/5 | Batch 1000/4800 | Cost: 0.0016\n",
      "Epoch: 1/5 | Batch 1250/4800 | Cost: 0.0073\n",
      "Epoch: 1/5 | Batch 1500/4800 | Cost: 0.0218\n",
      "Epoch: 1/5 | Batch 1750/4800 | Cost: 0.0048\n",
      "Epoch: 1/5 | Batch 2000/4800 | Cost: 0.0017\n",
      "Epoch: 1/5 | Batch 2250/4800 | Cost: 0.0071\n",
      "Epoch: 1/5 | Batch 2500/4800 | Cost: 0.0299\n",
      "Epoch: 1/5 | Batch 2750/4800 | Cost: 0.0019\n",
      "Epoch: 1/5 | Batch 3000/4800 | Cost: 0.0015\n",
      "Epoch: 1/5 | Batch 3250/4800 | Cost: 0.0621\n",
      "Epoch: 1/5 | Batch 3500/4800 | Cost: 0.0006\n",
      "Epoch: 1/5 | Batch 3750/4800 | Cost: 0.0010\n",
      "Epoch: 1/5 | Batch 4000/4800 | Cost: 0.0018\n",
      "Epoch: 1/5 | Batch 4250/4800 | Cost: 0.0004\n",
      "Epoch: 1/5 | Batch 4500/4800 | Cost: 0.0009\n",
      "Epoch: 1/5 | Batch 4750/4800 | Cost: 0.0009\n",
      "Training: Correct[239800] | Wrong[200] | Accuracy[99.92%] \n",
      "\n",
      "Epoch: 2/5 | Batch 0/4800 | Cost: 0.0020\n",
      "Epoch: 2/5 | Batch 250/4800 | Cost: 0.0051\n",
      "Epoch: 2/5 | Batch 500/4800 | Cost: 0.0005\n",
      "Epoch: 2/5 | Batch 750/4800 | Cost: 0.0005\n",
      "Epoch: 2/5 | Batch 1000/4800 | Cost: 0.0016\n",
      "Epoch: 2/5 | Batch 1250/4800 | Cost: 0.0013\n",
      "Epoch: 2/5 | Batch 1500/4800 | Cost: 0.0003\n",
      "Epoch: 2/5 | Batch 1750/4800 | Cost: 0.0159\n",
      "Epoch: 2/5 | Batch 2000/4800 | Cost: 0.0280\n",
      "Epoch: 2/5 | Batch 2250/4800 | Cost: 0.0005\n",
      "Epoch: 2/5 | Batch 2500/4800 | Cost: 0.0002\n",
      "Epoch: 2/5 | Batch 2750/4800 | Cost: 0.0073\n",
      "Epoch: 2/5 | Batch 3000/4800 | Cost: 0.0427\n",
      "Epoch: 2/5 | Batch 3250/4800 | Cost: 0.0003\n",
      "Epoch: 2/5 | Batch 3500/4800 | Cost: 0.0007\n",
      "Epoch: 2/5 | Batch 3750/4800 | Cost: 0.0002\n",
      "Epoch: 2/5 | Batch 4000/4800 | Cost: 0.0003\n",
      "Epoch: 2/5 | Batch 4250/4800 | Cost: 0.0058\n",
      "Epoch: 2/5 | Batch 4500/4800 | Cost: 0.0071\n",
      "Epoch: 2/5 | Batch 4750/4800 | Cost: 0.0003\n",
      "Training: Correct[239877] | Wrong[123] | Accuracy[99.95%] \n",
      "\n",
      "Epoch: 3/5 | Batch 0/4800 | Cost: 0.0010\n",
      "Epoch: 3/5 | Batch 250/4800 | Cost: 0.0004\n",
      "Epoch: 3/5 | Batch 500/4800 | Cost: 0.0001\n",
      "Epoch: 3/5 | Batch 750/4800 | Cost: 0.0009\n",
      "Epoch: 3/5 | Batch 1000/4800 | Cost: 0.0001\n",
      "Epoch: 3/5 | Batch 1250/4800 | Cost: 0.0006\n",
      "Epoch: 3/5 | Batch 1500/4800 | Cost: 0.0002\n",
      "Epoch: 3/5 | Batch 1750/4800 | Cost: 0.0003\n",
      "Epoch: 3/5 | Batch 2000/4800 | Cost: 0.0005\n",
      "Epoch: 3/5 | Batch 2250/4800 | Cost: 0.0003\n",
      "Epoch: 3/5 | Batch 2500/4800 | Cost: 0.0003\n",
      "Epoch: 3/5 | Batch 2750/4800 | Cost: 0.0001\n",
      "Epoch: 3/5 | Batch 3000/4800 | Cost: 0.0002\n",
      "Epoch: 3/5 | Batch 3250/4800 | Cost: 0.0004\n",
      "Epoch: 3/5 | Batch 3500/4800 | Cost: 0.0002\n",
      "Epoch: 3/5 | Batch 3750/4800 | Cost: 0.0094\n",
      "Epoch: 3/5 | Batch 4000/4800 | Cost: 0.0016\n",
      "Epoch: 3/5 | Batch 4250/4800 | Cost: 0.0001\n",
      "Epoch: 3/5 | Batch 4500/4800 | Cost: 0.0002\n",
      "Epoch: 3/5 | Batch 4750/4800 | Cost: 0.0009\n",
      "Training: Correct[239898] | Wrong[102] | Accuracy[99.96%] \n",
      "\n",
      "Epoch: 4/5 | Batch 0/4800 | Cost: 0.0018\n",
      "Epoch: 4/5 | Batch 250/4800 | Cost: 0.0002\n",
      "Epoch: 4/5 | Batch 500/4800 | Cost: 0.0001\n",
      "Epoch: 4/5 | Batch 750/4800 | Cost: 0.0009\n",
      "Epoch: 4/5 | Batch 1000/4800 | Cost: 0.0004\n",
      "Epoch: 4/5 | Batch 1250/4800 | Cost: 0.0001\n",
      "Epoch: 4/5 | Batch 1500/4800 | Cost: 0.0001\n",
      "Epoch: 4/5 | Batch 1750/4800 | Cost: 0.0001\n",
      "Epoch: 4/5 | Batch 2000/4800 | Cost: 0.0003\n",
      "Epoch: 4/5 | Batch 2250/4800 | Cost: 0.0005\n",
      "Epoch: 4/5 | Batch 2500/4800 | Cost: 0.0205\n",
      "Epoch: 4/5 | Batch 2750/4800 | Cost: 0.0016\n",
      "Epoch: 4/5 | Batch 3000/4800 | Cost: 0.0003\n",
      "Epoch: 4/5 | Batch 3250/4800 | Cost: 0.0096\n",
      "Epoch: 4/5 | Batch 3500/4800 | Cost: 0.0002\n",
      "Epoch: 4/5 | Batch 3750/4800 | Cost: 0.0001\n",
      "Epoch: 4/5 | Batch 4000/4800 | Cost: 0.0001\n",
      "Epoch: 4/5 | Batch 4250/4800 | Cost: 0.0002\n",
      "Epoch: 4/5 | Batch 4500/4800 | Cost: 0.0004\n",
      "Epoch: 4/5 | Batch 4750/4800 | Cost: 0.0009\n",
      "Training: Correct[239940] | Wrong[60] | Accuracy[99.97%] \n",
      "\n",
      "Epoch: 5/5 | Batch 0/4800 | Cost: 0.0024\n",
      "Epoch: 5/5 | Batch 250/4800 | Cost: 0.0001\n",
      "Epoch: 5/5 | Batch 500/4800 | Cost: 0.0409\n",
      "Epoch: 5/5 | Batch 750/4800 | Cost: 0.0001\n",
      "Epoch: 5/5 | Batch 1000/4800 | Cost: 0.0001\n",
      "Epoch: 5/5 | Batch 1250/4800 | Cost: 0.0003\n",
      "Epoch: 5/5 | Batch 1500/4800 | Cost: 0.0000\n",
      "Epoch: 5/5 | Batch 1750/4800 | Cost: 0.0001\n",
      "Epoch: 5/5 | Batch 2000/4800 | Cost: 0.0002\n",
      "Epoch: 5/5 | Batch 2250/4800 | Cost: 0.0001\n",
      "Epoch: 5/5 | Batch 2500/4800 | Cost: 0.0007\n",
      "Epoch: 5/5 | Batch 2750/4800 | Cost: 0.0021\n",
      "Epoch: 5/5 | Batch 3000/4800 | Cost: 0.0001\n",
      "Epoch: 5/5 | Batch 3250/4800 | Cost: 0.0002\n",
      "Epoch: 5/5 | Batch 3500/4800 | Cost: 0.0006\n",
      "Epoch: 5/5 | Batch 3750/4800 | Cost: 0.0001\n",
      "Epoch: 5/5 | Batch 4000/4800 | Cost: 0.0064\n",
      "Epoch: 5/5 | Batch 4250/4800 | Cost: 0.0002\n",
      "Epoch: 5/5 | Batch 4500/4800 | Cost: 0.0001\n",
      "Epoch: 5/5 | Batch 4750/4800 | Cost: 0.0008\n",
      "Training: Correct[239970] | Wrong[30] | Accuracy[99.99%] \n",
      "\n",
      "Training time: 614.56 seconds on cuda\n"
     ]
    }
   ],
   "source": [
    "fit(model_datasource, train_loader_datasource, epochs, learning_rate) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d97d915",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9d08b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = MLP(784, 200, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a044c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 60\n",
    "learning_rate = 0.08\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f189c7c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 | Batch 0/4800 | Cost: 2.3032\n",
      "Epoch: 1/30 | Batch 250/4800 | Cost: 0.9592\n",
      "Epoch: 1/30 | Batch 500/4800 | Cost: 0.7006\n",
      "Epoch: 1/30 | Batch 750/4800 | Cost: 0.7484\n",
      "Epoch: 1/30 | Batch 1000/4800 | Cost: 0.5136\n",
      "Epoch: 1/30 | Batch 1250/4800 | Cost: 0.4053\n",
      "Epoch: 1/30 | Batch 1500/4800 | Cost: 0.3880\n",
      "Epoch: 1/30 | Batch 1750/4800 | Cost: 0.3627\n",
      "Epoch: 1/30 | Batch 2000/4800 | Cost: 0.3981\n",
      "Epoch: 1/30 | Batch 2250/4800 | Cost: 0.4449\n",
      "Epoch: 1/30 | Batch 2500/4800 | Cost: 0.3490\n",
      "Epoch: 1/30 | Batch 2750/4800 | Cost: 0.2230\n",
      "Epoch: 1/30 | Batch 3000/4800 | Cost: 0.3808\n",
      "Epoch: 1/30 | Batch 3250/4800 | Cost: 0.3997\n",
      "Epoch: 1/30 | Batch 3500/4800 | Cost: 0.1927\n",
      "Epoch: 1/30 | Batch 3750/4800 | Cost: 0.3967\n",
      "Epoch: 1/30 | Batch 4000/4800 | Cost: 0.4604\n",
      "Epoch: 1/30 | Batch 4250/4800 | Cost: 0.4535\n",
      "Epoch: 1/30 | Batch 4500/4800 | Cost: 0.3809\n",
      "Epoch: 1/30 | Batch 4750/4800 | Cost: 0.4499\n",
      "Training: Correct[214481] | Wrong[25519] | Accuracy[89.37%] \n",
      "\n",
      "Epoch: 2/30 | Batch 0/4800 | Cost: 0.2557\n",
      "Epoch: 2/30 | Batch 250/4800 | Cost: 0.2058\n",
      "Epoch: 2/30 | Batch 500/4800 | Cost: 0.2532\n",
      "Epoch: 2/30 | Batch 750/4800 | Cost: 0.3102\n",
      "Epoch: 2/30 | Batch 1000/4800 | Cost: 0.4909\n",
      "Epoch: 2/30 | Batch 1250/4800 | Cost: 0.4393\n",
      "Epoch: 2/30 | Batch 1500/4800 | Cost: 0.3200\n",
      "Epoch: 2/30 | Batch 1750/4800 | Cost: 0.3979\n",
      "Epoch: 2/30 | Batch 2000/4800 | Cost: 0.1617\n",
      "Epoch: 2/30 | Batch 2250/4800 | Cost: 0.4404\n",
      "Epoch: 2/30 | Batch 2500/4800 | Cost: 0.2595\n",
      "Epoch: 2/30 | Batch 2750/4800 | Cost: 0.3603\n",
      "Epoch: 2/30 | Batch 3000/4800 | Cost: 0.3514\n",
      "Epoch: 2/30 | Batch 3250/4800 | Cost: 0.4371\n",
      "Epoch: 2/30 | Batch 3500/4800 | Cost: 0.1833\n",
      "Epoch: 2/30 | Batch 3750/4800 | Cost: 0.2392\n",
      "Epoch: 2/30 | Batch 4000/4800 | Cost: 0.3137\n",
      "Epoch: 2/30 | Batch 4250/4800 | Cost: 0.1829\n",
      "Epoch: 2/30 | Batch 4500/4800 | Cost: 0.3076\n",
      "Epoch: 2/30 | Batch 4750/4800 | Cost: 0.2992\n",
      "Training: Correct[219519] | Wrong[20481] | Accuracy[91.47%] \n",
      "\n",
      "Epoch: 3/30 | Batch 0/4800 | Cost: 0.2330\n",
      "Epoch: 3/30 | Batch 250/4800 | Cost: 0.2885\n",
      "Epoch: 3/30 | Batch 500/4800 | Cost: 0.2339\n",
      "Epoch: 3/30 | Batch 750/4800 | Cost: 0.2512\n",
      "Epoch: 3/30 | Batch 1000/4800 | Cost: 0.2979\n",
      "Epoch: 3/30 | Batch 1250/4800 | Cost: 0.1743\n",
      "Epoch: 3/30 | Batch 1500/4800 | Cost: 0.1408\n",
      "Epoch: 3/30 | Batch 1750/4800 | Cost: 0.2504\n",
      "Epoch: 3/30 | Batch 2000/4800 | Cost: 0.2075\n",
      "Epoch: 3/30 | Batch 2250/4800 | Cost: 0.2716\n",
      "Epoch: 3/30 | Batch 2500/4800 | Cost: 0.3633\n",
      "Epoch: 3/30 | Batch 2750/4800 | Cost: 0.3264\n",
      "Epoch: 3/30 | Batch 3000/4800 | Cost: 0.2725\n",
      "Epoch: 3/30 | Batch 3250/4800 | Cost: 0.2054\n",
      "Epoch: 3/30 | Batch 3500/4800 | Cost: 0.4179\n",
      "Epoch: 3/30 | Batch 3750/4800 | Cost: 0.2478\n",
      "Epoch: 3/30 | Batch 4000/4800 | Cost: 0.1728\n",
      "Epoch: 3/30 | Batch 4250/4800 | Cost: 0.3690\n",
      "Epoch: 3/30 | Batch 4500/4800 | Cost: 0.1690\n",
      "Epoch: 3/30 | Batch 4750/4800 | Cost: 0.3776\n",
      "Training: Correct[221137] | Wrong[18863] | Accuracy[92.14%] \n",
      "\n",
      "Epoch: 4/30 | Batch 0/4800 | Cost: 0.4914\n",
      "Epoch: 4/30 | Batch 250/4800 | Cost: 0.1885\n",
      "Epoch: 4/30 | Batch 500/4800 | Cost: 0.3569\n",
      "Epoch: 4/30 | Batch 750/4800 | Cost: 0.3213\n",
      "Epoch: 4/30 | Batch 1000/4800 | Cost: 0.1751\n",
      "Epoch: 4/30 | Batch 1250/4800 | Cost: 0.2403\n",
      "Epoch: 4/30 | Batch 1500/4800 | Cost: 0.1736\n",
      "Epoch: 4/30 | Batch 1750/4800 | Cost: 0.2316\n",
      "Epoch: 4/30 | Batch 2000/4800 | Cost: 0.1736\n",
      "Epoch: 4/30 | Batch 2250/4800 | Cost: 0.1935\n",
      "Epoch: 4/30 | Batch 2500/4800 | Cost: 0.2476\n",
      "Epoch: 4/30 | Batch 2750/4800 | Cost: 0.2314\n",
      "Epoch: 4/30 | Batch 3000/4800 | Cost: 0.1951\n",
      "Epoch: 4/30 | Batch 3250/4800 | Cost: 0.0920\n",
      "Epoch: 4/30 | Batch 3500/4800 | Cost: 0.2847\n",
      "Epoch: 4/30 | Batch 3750/4800 | Cost: 0.3045\n",
      "Epoch: 4/30 | Batch 4000/4800 | Cost: 0.1663\n",
      "Epoch: 4/30 | Batch 4250/4800 | Cost: 0.1459\n",
      "Epoch: 4/30 | Batch 4500/4800 | Cost: 0.2798\n",
      "Epoch: 4/30 | Batch 4750/4800 | Cost: 0.4843\n",
      "Training: Correct[221752] | Wrong[18248] | Accuracy[92.40%] \n",
      "\n",
      "Epoch: 5/30 | Batch 0/4800 | Cost: 0.2176\n",
      "Epoch: 5/30 | Batch 250/4800 | Cost: 0.3026\n",
      "Epoch: 5/30 | Batch 500/4800 | Cost: 0.4829\n",
      "Epoch: 5/30 | Batch 750/4800 | Cost: 0.2250\n",
      "Epoch: 5/30 | Batch 1000/4800 | Cost: 0.2827\n",
      "Epoch: 5/30 | Batch 1250/4800 | Cost: 0.1262\n",
      "Epoch: 5/30 | Batch 1500/4800 | Cost: 0.2104\n",
      "Epoch: 5/30 | Batch 1750/4800 | Cost: 0.2330\n",
      "Epoch: 5/30 | Batch 2000/4800 | Cost: 0.1246\n",
      "Epoch: 5/30 | Batch 2250/4800 | Cost: 0.4678\n",
      "Epoch: 5/30 | Batch 2500/4800 | Cost: 0.1518\n",
      "Epoch: 5/30 | Batch 2750/4800 | Cost: 0.1183\n",
      "Epoch: 5/30 | Batch 3000/4800 | Cost: 0.2867\n",
      "Epoch: 5/30 | Batch 3250/4800 | Cost: 0.5520\n",
      "Epoch: 5/30 | Batch 3500/4800 | Cost: 0.3748\n",
      "Epoch: 5/30 | Batch 3750/4800 | Cost: 0.1998\n",
      "Epoch: 5/30 | Batch 4000/4800 | Cost: 0.1039\n",
      "Epoch: 5/30 | Batch 4250/4800 | Cost: 0.2677\n",
      "Epoch: 5/30 | Batch 4500/4800 | Cost: 0.1745\n",
      "Epoch: 5/30 | Batch 4750/4800 | Cost: 0.2725\n",
      "Training: Correct[223564] | Wrong[16436] | Accuracy[93.15%] \n",
      "\n",
      "Epoch: 6/30 | Batch 0/4800 | Cost: 0.0605\n",
      "Epoch: 6/30 | Batch 250/4800 | Cost: 0.1874\n",
      "Epoch: 6/30 | Batch 500/4800 | Cost: 0.2085\n",
      "Epoch: 6/30 | Batch 750/4800 | Cost: 0.1587\n",
      "Epoch: 6/30 | Batch 1000/4800 | Cost: 0.1227\n",
      "Epoch: 6/30 | Batch 1250/4800 | Cost: 0.2163\n",
      "Epoch: 6/30 | Batch 1500/4800 | Cost: 0.1940\n",
      "Epoch: 6/30 | Batch 1750/4800 | Cost: 0.1948\n",
      "Epoch: 6/30 | Batch 2000/4800 | Cost: 0.1850\n",
      "Epoch: 6/30 | Batch 2250/4800 | Cost: 0.2894\n",
      "Epoch: 6/30 | Batch 2500/4800 | Cost: 0.1882\n",
      "Epoch: 6/30 | Batch 2750/4800 | Cost: 0.3563\n",
      "Epoch: 6/30 | Batch 3000/4800 | Cost: 0.1567\n",
      "Epoch: 6/30 | Batch 3250/4800 | Cost: 0.2216\n",
      "Epoch: 6/30 | Batch 3500/4800 | Cost: 0.1088\n",
      "Epoch: 6/30 | Batch 3750/4800 | Cost: 0.2375\n",
      "Epoch: 6/30 | Batch 4000/4800 | Cost: 0.1984\n",
      "Epoch: 6/30 | Batch 4250/4800 | Cost: 0.4837\n",
      "Epoch: 6/30 | Batch 4500/4800 | Cost: 0.2803\n",
      "Epoch: 6/30 | Batch 4750/4800 | Cost: 0.1887\n",
      "Training: Correct[224453] | Wrong[15547] | Accuracy[93.52%] \n",
      "\n",
      "Epoch: 7/30 | Batch 0/4800 | Cost: 0.1400\n",
      "Epoch: 7/30 | Batch 250/4800 | Cost: 0.2803\n",
      "Epoch: 7/30 | Batch 500/4800 | Cost: 0.3251\n",
      "Epoch: 7/30 | Batch 750/4800 | Cost: 0.1534\n",
      "Epoch: 7/30 | Batch 1000/4800 | Cost: 0.2478\n",
      "Epoch: 7/30 | Batch 1250/4800 | Cost: 0.0967\n",
      "Epoch: 7/30 | Batch 1500/4800 | Cost: 0.1774\n",
      "Epoch: 7/30 | Batch 1750/4800 | Cost: 0.1176\n",
      "Epoch: 7/30 | Batch 2000/4800 | Cost: 0.1757\n",
      "Epoch: 7/30 | Batch 2250/4800 | Cost: 0.1638\n",
      "Epoch: 7/30 | Batch 2500/4800 | Cost: 0.1967\n",
      "Epoch: 7/30 | Batch 2750/4800 | Cost: 0.1965\n",
      "Epoch: 7/30 | Batch 3000/4800 | Cost: 0.1418\n",
      "Epoch: 7/30 | Batch 3250/4800 | Cost: 0.1491\n",
      "Epoch: 7/30 | Batch 3500/4800 | Cost: 0.1778\n",
      "Epoch: 7/30 | Batch 3750/4800 | Cost: 0.3819\n",
      "Epoch: 7/30 | Batch 4000/4800 | Cost: 0.2257\n",
      "Epoch: 7/30 | Batch 4250/4800 | Cost: 0.1079\n",
      "Epoch: 7/30 | Batch 4500/4800 | Cost: 0.2068\n",
      "Epoch: 7/30 | Batch 4750/4800 | Cost: 0.1321\n",
      "Training: Correct[225474] | Wrong[14526] | Accuracy[93.95%] \n",
      "\n",
      "Epoch: 8/30 | Batch 0/4800 | Cost: 0.1670\n",
      "Epoch: 8/30 | Batch 250/4800 | Cost: 0.1739\n",
      "Epoch: 8/30 | Batch 500/4800 | Cost: 0.2040\n",
      "Epoch: 8/30 | Batch 750/4800 | Cost: 0.1016\n",
      "Epoch: 8/30 | Batch 1000/4800 | Cost: 0.0950\n",
      "Epoch: 8/30 | Batch 1250/4800 | Cost: 0.2324\n",
      "Epoch: 8/30 | Batch 1500/4800 | Cost: 0.2739\n",
      "Epoch: 8/30 | Batch 1750/4800 | Cost: 0.0518\n",
      "Epoch: 8/30 | Batch 2000/4800 | Cost: 0.3140\n",
      "Epoch: 8/30 | Batch 2250/4800 | Cost: 0.2203\n",
      "Epoch: 8/30 | Batch 2500/4800 | Cost: 0.1608\n",
      "Epoch: 8/30 | Batch 2750/4800 | Cost: 0.2971\n",
      "Epoch: 8/30 | Batch 3000/4800 | Cost: 0.1539\n",
      "Epoch: 8/30 | Batch 3250/4800 | Cost: 0.2786\n",
      "Epoch: 8/30 | Batch 3500/4800 | Cost: 0.2171\n",
      "Epoch: 8/30 | Batch 3750/4800 | Cost: 0.2828\n",
      "Epoch: 8/30 | Batch 4000/4800 | Cost: 0.2076\n",
      "Epoch: 8/30 | Batch 4250/4800 | Cost: 0.1838\n",
      "Epoch: 8/30 | Batch 4500/4800 | Cost: 0.1133\n",
      "Epoch: 8/30 | Batch 4750/4800 | Cost: 0.1235\n",
      "Training: Correct[225637] | Wrong[14363] | Accuracy[94.02%] \n",
      "\n",
      "Epoch: 9/30 | Batch 0/4800 | Cost: 0.1636\n",
      "Epoch: 9/30 | Batch 250/4800 | Cost: 0.2736\n",
      "Epoch: 9/30 | Batch 500/4800 | Cost: 0.2323\n",
      "Epoch: 9/30 | Batch 750/4800 | Cost: 0.2586\n",
      "Epoch: 9/30 | Batch 1000/4800 | Cost: 0.1591\n",
      "Epoch: 9/30 | Batch 1250/4800 | Cost: 0.1724\n",
      "Epoch: 9/30 | Batch 1500/4800 | Cost: 0.2220\n",
      "Epoch: 9/30 | Batch 1750/4800 | Cost: 0.0470\n",
      "Epoch: 9/30 | Batch 2000/4800 | Cost: 0.2660\n",
      "Epoch: 9/30 | Batch 2250/4800 | Cost: 0.3908\n",
      "Epoch: 9/30 | Batch 2500/4800 | Cost: 0.1545\n",
      "Epoch: 9/30 | Batch 2750/4800 | Cost: 0.1853\n",
      "Epoch: 9/30 | Batch 3000/4800 | Cost: 0.1130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/30 | Batch 3250/4800 | Cost: 0.1647\n",
      "Epoch: 9/30 | Batch 3500/4800 | Cost: 0.2368\n",
      "Epoch: 9/30 | Batch 3750/4800 | Cost: 0.2820\n",
      "Epoch: 9/30 | Batch 4000/4800 | Cost: 0.1946\n",
      "Epoch: 9/30 | Batch 4250/4800 | Cost: 0.2193\n",
      "Epoch: 9/30 | Batch 4500/4800 | Cost: 0.4005\n",
      "Epoch: 9/30 | Batch 4750/4800 | Cost: 0.0938\n",
      "Training: Correct[224469] | Wrong[15531] | Accuracy[93.53%] \n",
      "\n",
      "Epoch: 10/30 | Batch 0/4800 | Cost: 0.2915\n",
      "Epoch: 10/30 | Batch 250/4800 | Cost: 0.1376\n",
      "Epoch: 10/30 | Batch 500/4800 | Cost: 0.1723\n",
      "Epoch: 10/30 | Batch 750/4800 | Cost: 0.2051\n",
      "Epoch: 10/30 | Batch 1000/4800 | Cost: 0.3097\n",
      "Epoch: 10/30 | Batch 1250/4800 | Cost: 0.1144\n",
      "Epoch: 10/30 | Batch 1500/4800 | Cost: 0.2970\n",
      "Epoch: 10/30 | Batch 1750/4800 | Cost: 0.1659\n",
      "Epoch: 10/30 | Batch 2000/4800 | Cost: 0.1674\n",
      "Epoch: 10/30 | Batch 2250/4800 | Cost: 0.0507\n",
      "Epoch: 10/30 | Batch 2500/4800 | Cost: 0.1837\n",
      "Epoch: 10/30 | Batch 2750/4800 | Cost: 0.2552\n",
      "Epoch: 10/30 | Batch 3000/4800 | Cost: 0.1909\n",
      "Epoch: 10/30 | Batch 3250/4800 | Cost: 0.1770\n",
      "Epoch: 10/30 | Batch 3500/4800 | Cost: 0.1438\n",
      "Epoch: 10/30 | Batch 3750/4800 | Cost: 0.1373\n",
      "Epoch: 10/30 | Batch 4000/4800 | Cost: 0.0295\n",
      "Epoch: 10/30 | Batch 4250/4800 | Cost: 0.1158\n",
      "Epoch: 10/30 | Batch 4500/4800 | Cost: 0.2300\n",
      "Epoch: 10/30 | Batch 4750/4800 | Cost: 0.2611\n",
      "Training: Correct[226487] | Wrong[13513] | Accuracy[94.37%] \n",
      "\n",
      "Epoch: 11/30 | Batch 0/4800 | Cost: 0.0850\n",
      "Epoch: 11/30 | Batch 250/4800 | Cost: 0.1952\n",
      "Epoch: 11/30 | Batch 500/4800 | Cost: 0.1633\n",
      "Epoch: 11/30 | Batch 750/4800 | Cost: 0.1949\n",
      "Epoch: 11/30 | Batch 1000/4800 | Cost: 0.1359\n",
      "Epoch: 11/30 | Batch 1250/4800 | Cost: 0.2189\n",
      "Epoch: 11/30 | Batch 1500/4800 | Cost: 0.0879\n",
      "Epoch: 11/30 | Batch 1750/4800 | Cost: 0.1420\n",
      "Epoch: 11/30 | Batch 2000/4800 | Cost: 0.0697\n",
      "Epoch: 11/30 | Batch 2250/4800 | Cost: 0.2540\n",
      "Epoch: 11/30 | Batch 2500/4800 | Cost: 0.3222\n",
      "Epoch: 11/30 | Batch 2750/4800 | Cost: 0.1428\n",
      "Epoch: 11/30 | Batch 3000/4800 | Cost: 0.1846\n",
      "Epoch: 11/30 | Batch 3250/4800 | Cost: 0.1628\n",
      "Epoch: 11/30 | Batch 3500/4800 | Cost: 0.1604\n",
      "Epoch: 11/30 | Batch 3750/4800 | Cost: 0.3575\n",
      "Epoch: 11/30 | Batch 4000/4800 | Cost: 0.1993\n",
      "Epoch: 11/30 | Batch 4250/4800 | Cost: 0.0742\n",
      "Epoch: 11/30 | Batch 4500/4800 | Cost: 0.1403\n",
      "Epoch: 11/30 | Batch 4750/4800 | Cost: 0.1391\n",
      "Training: Correct[227001] | Wrong[12999] | Accuracy[94.58%] \n",
      "\n",
      "Epoch: 12/30 | Batch 0/4800 | Cost: 0.0895\n",
      "Epoch: 12/30 | Batch 250/4800 | Cost: 0.1365\n",
      "Epoch: 12/30 | Batch 500/4800 | Cost: 0.2247\n",
      "Epoch: 12/30 | Batch 750/4800 | Cost: 0.0659\n",
      "Epoch: 12/30 | Batch 1000/4800 | Cost: 0.2528\n",
      "Epoch: 12/30 | Batch 1250/4800 | Cost: 0.1003\n",
      "Epoch: 12/30 | Batch 1500/4800 | Cost: 0.2483\n",
      "Epoch: 12/30 | Batch 1750/4800 | Cost: 0.2791\n",
      "Epoch: 12/30 | Batch 2000/4800 | Cost: 0.1077\n",
      "Epoch: 12/30 | Batch 2250/4800 | Cost: 0.0878\n",
      "Epoch: 12/30 | Batch 2500/4800 | Cost: 0.1429\n",
      "Epoch: 12/30 | Batch 2750/4800 | Cost: 0.1288\n",
      "Epoch: 12/30 | Batch 3000/4800 | Cost: 0.0617\n",
      "Epoch: 12/30 | Batch 3250/4800 | Cost: 0.0996\n",
      "Epoch: 12/30 | Batch 3500/4800 | Cost: 0.3470\n",
      "Epoch: 12/30 | Batch 3750/4800 | Cost: 0.2651\n",
      "Epoch: 12/30 | Batch 4000/4800 | Cost: 0.3616\n",
      "Epoch: 12/30 | Batch 4250/4800 | Cost: 0.1551\n",
      "Epoch: 12/30 | Batch 4500/4800 | Cost: 0.3502\n",
      "Epoch: 12/30 | Batch 4750/4800 | Cost: 0.1907\n",
      "Training: Correct[227391] | Wrong[12609] | Accuracy[94.75%] \n",
      "\n",
      "Epoch: 13/30 | Batch 0/4800 | Cost: 0.1724\n",
      "Epoch: 13/30 | Batch 250/4800 | Cost: 0.0927\n",
      "Epoch: 13/30 | Batch 500/4800 | Cost: 0.1743\n",
      "Epoch: 13/30 | Batch 750/4800 | Cost: 0.1046\n",
      "Epoch: 13/30 | Batch 1000/4800 | Cost: 0.2525\n",
      "Epoch: 13/30 | Batch 1250/4800 | Cost: 0.1449\n",
      "Epoch: 13/30 | Batch 1500/4800 | Cost: 0.2717\n",
      "Epoch: 13/30 | Batch 1750/4800 | Cost: 0.0706\n",
      "Epoch: 13/30 | Batch 2000/4800 | Cost: 0.1406\n",
      "Epoch: 13/30 | Batch 2250/4800 | Cost: 0.1144\n",
      "Epoch: 13/30 | Batch 2500/4800 | Cost: 0.2066\n",
      "Epoch: 13/30 | Batch 2750/4800 | Cost: 0.0841\n",
      "Epoch: 13/30 | Batch 3000/4800 | Cost: 0.1344\n",
      "Epoch: 13/30 | Batch 3250/4800 | Cost: 0.1440\n",
      "Epoch: 13/30 | Batch 3500/4800 | Cost: 0.1617\n",
      "Epoch: 13/30 | Batch 3750/4800 | Cost: 0.1563\n",
      "Epoch: 13/30 | Batch 4000/4800 | Cost: 0.1026\n",
      "Epoch: 13/30 | Batch 4250/4800 | Cost: 0.0906\n",
      "Epoch: 13/30 | Batch 4500/4800 | Cost: 0.1885\n",
      "Epoch: 13/30 | Batch 4750/4800 | Cost: 0.1216\n",
      "Training: Correct[227357] | Wrong[12643] | Accuracy[94.73%] \n",
      "\n",
      "Epoch: 14/30 | Batch 0/4800 | Cost: 0.1017\n",
      "Epoch: 14/30 | Batch 250/4800 | Cost: 0.0483\n",
      "Epoch: 14/30 | Batch 500/4800 | Cost: 0.1961\n",
      "Epoch: 14/30 | Batch 750/4800 | Cost: 0.1087\n",
      "Epoch: 14/30 | Batch 1000/4800 | Cost: 0.1313\n",
      "Epoch: 14/30 | Batch 1250/4800 | Cost: 0.2192\n",
      "Epoch: 14/30 | Batch 1500/4800 | Cost: 0.0946\n",
      "Epoch: 14/30 | Batch 1750/4800 | Cost: 0.2326\n",
      "Epoch: 14/30 | Batch 2000/4800 | Cost: 0.1433\n",
      "Epoch: 14/30 | Batch 2250/4800 | Cost: 0.2078\n",
      "Epoch: 14/30 | Batch 2500/4800 | Cost: 0.1681\n",
      "Epoch: 14/30 | Batch 2750/4800 | Cost: 0.2716\n",
      "Epoch: 14/30 | Batch 3000/4800 | Cost: 0.2050\n",
      "Epoch: 14/30 | Batch 3250/4800 | Cost: 0.1491\n",
      "Epoch: 14/30 | Batch 3500/4800 | Cost: 0.1475\n",
      "Epoch: 14/30 | Batch 3750/4800 | Cost: 0.2334\n",
      "Epoch: 14/30 | Batch 4000/4800 | Cost: 0.1031\n",
      "Epoch: 14/30 | Batch 4250/4800 | Cost: 0.1171\n",
      "Epoch: 14/30 | Batch 4500/4800 | Cost: 0.0560\n",
      "Epoch: 14/30 | Batch 4750/4800 | Cost: 0.1629\n",
      "Training: Correct[227784] | Wrong[12216] | Accuracy[94.91%] \n",
      "\n",
      "Epoch: 15/30 | Batch 0/4800 | Cost: 0.2101\n",
      "Epoch: 15/30 | Batch 250/4800 | Cost: 0.2044\n",
      "Epoch: 15/30 | Batch 500/4800 | Cost: 0.1940\n",
      "Epoch: 15/30 | Batch 750/4800 | Cost: 0.1666\n",
      "Epoch: 15/30 | Batch 1000/4800 | Cost: 0.1280\n",
      "Epoch: 15/30 | Batch 1250/4800 | Cost: 0.1110\n",
      "Epoch: 15/30 | Batch 1500/4800 | Cost: 0.1191\n",
      "Epoch: 15/30 | Batch 1750/4800 | Cost: 0.1451\n",
      "Epoch: 15/30 | Batch 2000/4800 | Cost: 0.0625\n",
      "Epoch: 15/30 | Batch 2250/4800 | Cost: 0.1589\n",
      "Epoch: 15/30 | Batch 2500/4800 | Cost: 0.1735\n",
      "Epoch: 15/30 | Batch 2750/4800 | Cost: 0.1076\n",
      "Epoch: 15/30 | Batch 3000/4800 | Cost: 0.1143\n",
      "Epoch: 15/30 | Batch 3250/4800 | Cost: 0.0730\n",
      "Epoch: 15/30 | Batch 3500/4800 | Cost: 0.1398\n",
      "Epoch: 15/30 | Batch 3750/4800 | Cost: 0.1742\n",
      "Epoch: 15/30 | Batch 4000/4800 | Cost: 0.1897\n",
      "Epoch: 15/30 | Batch 4250/4800 | Cost: 0.0781\n",
      "Epoch: 15/30 | Batch 4500/4800 | Cost: 0.2852\n",
      "Epoch: 15/30 | Batch 4750/4800 | Cost: 0.1080\n",
      "Training: Correct[227912] | Wrong[12088] | Accuracy[94.96%] \n",
      "\n",
      "Epoch: 16/30 | Batch 0/4800 | Cost: 0.0315\n",
      "Epoch: 16/30 | Batch 250/4800 | Cost: 0.1174\n",
      "Epoch: 16/30 | Batch 500/4800 | Cost: 0.1029\n",
      "Epoch: 16/30 | Batch 750/4800 | Cost: 0.1891\n",
      "Epoch: 16/30 | Batch 1000/4800 | Cost: 0.1605\n",
      "Epoch: 16/30 | Batch 1250/4800 | Cost: 0.0801\n",
      "Epoch: 16/30 | Batch 1500/4800 | Cost: 0.1696\n",
      "Epoch: 16/30 | Batch 1750/4800 | Cost: 0.0641\n",
      "Epoch: 16/30 | Batch 2000/4800 | Cost: 0.1872\n",
      "Epoch: 16/30 | Batch 2250/4800 | Cost: 0.1066\n",
      "Epoch: 16/30 | Batch 2500/4800 | Cost: 0.1810\n",
      "Epoch: 16/30 | Batch 2750/4800 | Cost: 0.0759\n",
      "Epoch: 16/30 | Batch 3000/4800 | Cost: 0.4444\n",
      "Epoch: 16/30 | Batch 3250/4800 | Cost: 0.1385\n",
      "Epoch: 16/30 | Batch 3500/4800 | Cost: 0.1161\n",
      "Epoch: 16/30 | Batch 3750/4800 | Cost: 0.2696\n",
      "Epoch: 16/30 | Batch 4000/4800 | Cost: 0.1497\n",
      "Epoch: 16/30 | Batch 4250/4800 | Cost: 0.1643\n",
      "Epoch: 16/30 | Batch 4500/4800 | Cost: 0.2042\n",
      "Epoch: 16/30 | Batch 4750/4800 | Cost: 0.1388\n",
      "Training: Correct[228384] | Wrong[11616] | Accuracy[95.16%] \n",
      "\n",
      "Epoch: 17/30 | Batch 0/4800 | Cost: 0.1562\n",
      "Epoch: 17/30 | Batch 250/4800 | Cost: 0.0463\n",
      "Epoch: 17/30 | Batch 500/4800 | Cost: 0.1040\n",
      "Epoch: 17/30 | Batch 750/4800 | Cost: 0.0635\n",
      "Epoch: 17/30 | Batch 1000/4800 | Cost: 0.2840\n",
      "Epoch: 17/30 | Batch 1250/4800 | Cost: 0.2640\n",
      "Epoch: 17/30 | Batch 1500/4800 | Cost: 0.0990\n",
      "Epoch: 17/30 | Batch 1750/4800 | Cost: 0.2352\n",
      "Epoch: 17/30 | Batch 2000/4800 | Cost: 0.1694\n",
      "Epoch: 17/30 | Batch 2250/4800 | Cost: 0.1849\n",
      "Epoch: 17/30 | Batch 2500/4800 | Cost: 0.1272\n",
      "Epoch: 17/30 | Batch 2750/4800 | Cost: 0.0814\n",
      "Epoch: 17/30 | Batch 3000/4800 | Cost: 0.1051\n",
      "Epoch: 17/30 | Batch 3250/4800 | Cost: 0.1302\n",
      "Epoch: 17/30 | Batch 3500/4800 | Cost: 0.2634\n",
      "Epoch: 17/30 | Batch 3750/4800 | Cost: 0.1748\n",
      "Epoch: 17/30 | Batch 4000/4800 | Cost: 0.0628\n",
      "Epoch: 17/30 | Batch 4250/4800 | Cost: 0.2445\n",
      "Epoch: 17/30 | Batch 4500/4800 | Cost: 0.1390\n",
      "Epoch: 17/30 | Batch 4750/4800 | Cost: 0.1153\n",
      "Training: Correct[227911] | Wrong[12089] | Accuracy[94.96%] \n",
      "\n",
      "Epoch: 18/30 | Batch 0/4800 | Cost: 0.3086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/30 | Batch 250/4800 | Cost: 0.1449\n",
      "Epoch: 18/30 | Batch 500/4800 | Cost: 0.1923\n",
      "Epoch: 18/30 | Batch 750/4800 | Cost: 0.1929\n",
      "Epoch: 18/30 | Batch 1000/4800 | Cost: 0.1407\n",
      "Epoch: 18/30 | Batch 1250/4800 | Cost: 0.1138\n",
      "Epoch: 18/30 | Batch 1500/4800 | Cost: 0.2157\n",
      "Epoch: 18/30 | Batch 1750/4800 | Cost: 0.2262\n",
      "Epoch: 18/30 | Batch 2000/4800 | Cost: 0.1742\n",
      "Epoch: 18/30 | Batch 2250/4800 | Cost: 0.0555\n",
      "Epoch: 18/30 | Batch 2500/4800 | Cost: 0.1733\n",
      "Epoch: 18/30 | Batch 2750/4800 | Cost: 0.2251\n",
      "Epoch: 18/30 | Batch 3000/4800 | Cost: 0.0744\n",
      "Epoch: 18/30 | Batch 3250/4800 | Cost: 0.1766\n",
      "Epoch: 18/30 | Batch 3500/4800 | Cost: 0.2431\n",
      "Epoch: 18/30 | Batch 3750/4800 | Cost: 0.2216\n",
      "Epoch: 18/30 | Batch 4000/4800 | Cost: 0.0554\n",
      "Epoch: 18/30 | Batch 4250/4800 | Cost: 0.1842\n",
      "Epoch: 18/30 | Batch 4500/4800 | Cost: 0.2640\n",
      "Epoch: 18/30 | Batch 4750/4800 | Cost: 0.2081\n",
      "Training: Correct[228075] | Wrong[11925] | Accuracy[95.03%] \n",
      "\n",
      "Epoch: 19/30 | Batch 0/4800 | Cost: 0.0815\n",
      "Epoch: 19/30 | Batch 250/4800 | Cost: 0.1319\n",
      "Epoch: 19/30 | Batch 500/4800 | Cost: 0.0660\n",
      "Epoch: 19/30 | Batch 750/4800 | Cost: 0.1376\n",
      "Epoch: 19/30 | Batch 1000/4800 | Cost: 0.1426\n",
      "Epoch: 19/30 | Batch 1250/4800 | Cost: 0.1158\n",
      "Epoch: 19/30 | Batch 1500/4800 | Cost: 0.1401\n",
      "Epoch: 19/30 | Batch 1750/4800 | Cost: 0.1307\n",
      "Epoch: 19/30 | Batch 2000/4800 | Cost: 0.0890\n",
      "Epoch: 19/30 | Batch 2250/4800 | Cost: 0.1502\n",
      "Epoch: 19/30 | Batch 2500/4800 | Cost: 0.0608\n",
      "Epoch: 19/30 | Batch 2750/4800 | Cost: 0.0632\n",
      "Epoch: 19/30 | Batch 3000/4800 | Cost: 0.0398\n",
      "Epoch: 19/30 | Batch 3250/4800 | Cost: 0.2471\n",
      "Epoch: 19/30 | Batch 3500/4800 | Cost: 0.1752\n",
      "Epoch: 19/30 | Batch 3750/4800 | Cost: 0.0658\n",
      "Epoch: 19/30 | Batch 4000/4800 | Cost: 0.1510\n",
      "Epoch: 19/30 | Batch 4250/4800 | Cost: 0.0858\n",
      "Epoch: 19/30 | Batch 4500/4800 | Cost: 0.0811\n",
      "Epoch: 19/30 | Batch 4750/4800 | Cost: 0.0948\n",
      "Training: Correct[229035] | Wrong[10965] | Accuracy[95.43%] \n",
      "\n",
      "Epoch: 20/30 | Batch 0/4800 | Cost: 0.2355\n",
      "Epoch: 20/30 | Batch 250/4800 | Cost: 0.1602\n",
      "Epoch: 20/30 | Batch 500/4800 | Cost: 0.0786\n",
      "Epoch: 20/30 | Batch 750/4800 | Cost: 0.2537\n",
      "Epoch: 20/30 | Batch 1000/4800 | Cost: 0.0639\n",
      "Epoch: 20/30 | Batch 1250/4800 | Cost: 0.1283\n",
      "Epoch: 20/30 | Batch 1500/4800 | Cost: 0.1026\n",
      "Epoch: 20/30 | Batch 1750/4800 | Cost: 0.1718\n",
      "Epoch: 20/30 | Batch 2000/4800 | Cost: 0.0965\n",
      "Epoch: 20/30 | Batch 2250/4800 | Cost: 0.2210\n",
      "Epoch: 20/30 | Batch 2500/4800 | Cost: 0.1441\n",
      "Epoch: 20/30 | Batch 2750/4800 | Cost: 0.1473\n",
      "Epoch: 20/30 | Batch 3000/4800 | Cost: 0.1272\n",
      "Epoch: 20/30 | Batch 3250/4800 | Cost: 0.1341\n",
      "Epoch: 20/30 | Batch 3500/4800 | Cost: 0.2724\n",
      "Epoch: 20/30 | Batch 3750/4800 | Cost: 0.0998\n",
      "Epoch: 20/30 | Batch 4000/4800 | Cost: 0.0775\n",
      "Epoch: 20/30 | Batch 4250/4800 | Cost: 0.1617\n",
      "Epoch: 20/30 | Batch 4500/4800 | Cost: 0.1399\n",
      "Epoch: 20/30 | Batch 4750/4800 | Cost: 0.1549\n",
      "Training: Correct[229376] | Wrong[10624] | Accuracy[95.57%] \n",
      "\n",
      "Epoch: 21/30 | Batch 0/4800 | Cost: 0.1226\n",
      "Epoch: 21/30 | Batch 250/4800 | Cost: 0.3737\n",
      "Epoch: 21/30 | Batch 500/4800 | Cost: 0.2784\n",
      "Epoch: 21/30 | Batch 750/4800 | Cost: 0.1424\n",
      "Epoch: 21/30 | Batch 1000/4800 | Cost: 0.1598\n",
      "Epoch: 21/30 | Batch 1250/4800 | Cost: 0.0380\n",
      "Epoch: 21/30 | Batch 1500/4800 | Cost: 0.1297\n",
      "Epoch: 21/30 | Batch 1750/4800 | Cost: 0.1551\n",
      "Epoch: 21/30 | Batch 2000/4800 | Cost: 0.1788\n",
      "Epoch: 21/30 | Batch 2250/4800 | Cost: 0.1573\n",
      "Epoch: 21/30 | Batch 2500/4800 | Cost: 0.1842\n",
      "Epoch: 21/30 | Batch 2750/4800 | Cost: 0.2037\n",
      "Epoch: 21/30 | Batch 3000/4800 | Cost: 0.1145\n",
      "Epoch: 21/30 | Batch 3250/4800 | Cost: 0.0917\n",
      "Epoch: 21/30 | Batch 3500/4800 | Cost: 0.1289\n",
      "Epoch: 21/30 | Batch 3750/4800 | Cost: 0.0965\n",
      "Epoch: 21/30 | Batch 4000/4800 | Cost: 0.0644\n",
      "Epoch: 21/30 | Batch 4250/4800 | Cost: 0.0895\n",
      "Epoch: 21/30 | Batch 4500/4800 | Cost: 0.0314\n",
      "Epoch: 21/30 | Batch 4750/4800 | Cost: 0.2333\n",
      "Training: Correct[229203] | Wrong[10797] | Accuracy[95.50%] \n",
      "\n",
      "Epoch: 22/30 | Batch 0/4800 | Cost: 0.1496\n",
      "Epoch: 22/30 | Batch 250/4800 | Cost: 0.0718\n",
      "Epoch: 22/30 | Batch 500/4800 | Cost: 0.1235\n",
      "Epoch: 22/30 | Batch 750/4800 | Cost: 0.0390\n",
      "Epoch: 22/30 | Batch 1000/4800 | Cost: 0.1204\n",
      "Epoch: 22/30 | Batch 1250/4800 | Cost: 0.1315\n",
      "Epoch: 22/30 | Batch 1500/4800 | Cost: 0.1975\n",
      "Epoch: 22/30 | Batch 1750/4800 | Cost: 0.5459\n",
      "Epoch: 22/30 | Batch 2000/4800 | Cost: 0.2645\n",
      "Epoch: 22/30 | Batch 2250/4800 | Cost: 0.1226\n",
      "Epoch: 22/30 | Batch 2500/4800 | Cost: 0.1048\n",
      "Epoch: 22/30 | Batch 2750/4800 | Cost: 0.1060\n",
      "Epoch: 22/30 | Batch 3000/4800 | Cost: 0.1397\n",
      "Epoch: 22/30 | Batch 3250/4800 | Cost: 0.1962\n",
      "Epoch: 22/30 | Batch 3500/4800 | Cost: 0.1495\n",
      "Epoch: 22/30 | Batch 3750/4800 | Cost: 0.1775\n",
      "Epoch: 22/30 | Batch 4000/4800 | Cost: 0.1909\n",
      "Epoch: 22/30 | Batch 4250/4800 | Cost: 0.1174\n",
      "Epoch: 22/30 | Batch 4500/4800 | Cost: 0.1785\n",
      "Epoch: 22/30 | Batch 4750/4800 | Cost: 0.1198\n",
      "Training: Correct[229853] | Wrong[10147] | Accuracy[95.77%] \n",
      "\n",
      "Epoch: 23/30 | Batch 0/4800 | Cost: 0.0502\n",
      "Epoch: 23/30 | Batch 250/4800 | Cost: 0.1322\n",
      "Epoch: 23/30 | Batch 500/4800 | Cost: 0.1712\n",
      "Epoch: 23/30 | Batch 750/4800 | Cost: 0.1385\n",
      "Epoch: 23/30 | Batch 1000/4800 | Cost: 0.1151\n",
      "Epoch: 23/30 | Batch 1250/4800 | Cost: 0.1578\n",
      "Epoch: 23/30 | Batch 1500/4800 | Cost: 0.0904\n",
      "Epoch: 23/30 | Batch 1750/4800 | Cost: 0.1675\n",
      "Epoch: 23/30 | Batch 2000/4800 | Cost: 0.0766\n",
      "Epoch: 23/30 | Batch 2250/4800 | Cost: 0.1520\n",
      "Epoch: 23/30 | Batch 2500/4800 | Cost: 0.1191\n",
      "Epoch: 23/30 | Batch 2750/4800 | Cost: 0.1322\n",
      "Epoch: 23/30 | Batch 3000/4800 | Cost: 0.0435\n",
      "Epoch: 23/30 | Batch 3250/4800 | Cost: 0.0575\n",
      "Epoch: 23/30 | Batch 3500/4800 | Cost: 0.0401\n",
      "Epoch: 23/30 | Batch 3750/4800 | Cost: 0.0942\n",
      "Epoch: 23/30 | Batch 4000/4800 | Cost: 0.0834\n",
      "Epoch: 23/30 | Batch 4250/4800 | Cost: 0.1919\n",
      "Epoch: 23/30 | Batch 4500/4800 | Cost: 0.4812\n",
      "Epoch: 23/30 | Batch 4750/4800 | Cost: 0.1068\n",
      "Training: Correct[227959] | Wrong[12041] | Accuracy[94.98%] \n",
      "\n",
      "Epoch: 24/30 | Batch 0/4800 | Cost: 0.1192\n",
      "Epoch: 24/30 | Batch 250/4800 | Cost: 0.0973\n",
      "Epoch: 24/30 | Batch 500/4800 | Cost: 0.0433\n",
      "Epoch: 24/30 | Batch 750/4800 | Cost: 0.0503\n",
      "Epoch: 24/30 | Batch 1000/4800 | Cost: 0.1587\n",
      "Epoch: 24/30 | Batch 1250/4800 | Cost: 0.0657\n",
      "Epoch: 24/30 | Batch 1500/4800 | Cost: 0.2487\n",
      "Epoch: 24/30 | Batch 1750/4800 | Cost: 0.1082\n",
      "Epoch: 24/30 | Batch 2000/4800 | Cost: 0.0994\n",
      "Epoch: 24/30 | Batch 2250/4800 | Cost: 0.1356\n",
      "Epoch: 24/30 | Batch 2500/4800 | Cost: 0.0565\n",
      "Epoch: 24/30 | Batch 2750/4800 | Cost: 0.1260\n",
      "Epoch: 24/30 | Batch 3000/4800 | Cost: 0.1228\n",
      "Epoch: 24/30 | Batch 3250/4800 | Cost: 0.0468\n",
      "Epoch: 24/30 | Batch 3500/4800 | Cost: 0.0540\n",
      "Epoch: 24/30 | Batch 3750/4800 | Cost: 0.2364\n",
      "Epoch: 24/30 | Batch 4000/4800 | Cost: 0.1191\n",
      "Epoch: 24/30 | Batch 4250/4800 | Cost: 0.1133\n",
      "Epoch: 24/30 | Batch 4500/4800 | Cost: 0.1203\n",
      "Epoch: 24/30 | Batch 4750/4800 | Cost: 0.1466\n",
      "Training: Correct[229481] | Wrong[10519] | Accuracy[95.62%] \n",
      "\n",
      "Epoch: 25/30 | Batch 0/4800 | Cost: 0.0607\n",
      "Epoch: 25/30 | Batch 250/4800 | Cost: 0.0567\n",
      "Epoch: 25/30 | Batch 500/4800 | Cost: 0.0529\n",
      "Epoch: 25/30 | Batch 750/4800 | Cost: 0.2836\n",
      "Epoch: 25/30 | Batch 1000/4800 | Cost: 0.2200\n",
      "Epoch: 25/30 | Batch 1250/4800 | Cost: 0.1225\n",
      "Epoch: 25/30 | Batch 1500/4800 | Cost: 0.0201\n",
      "Epoch: 25/30 | Batch 1750/4800 | Cost: 0.1408\n",
      "Epoch: 25/30 | Batch 2000/4800 | Cost: 0.0803\n",
      "Epoch: 25/30 | Batch 2250/4800 | Cost: 0.1791\n",
      "Epoch: 25/30 | Batch 2500/4800 | Cost: 0.0918\n",
      "Epoch: 25/30 | Batch 2750/4800 | Cost: 0.3324\n",
      "Epoch: 25/30 | Batch 3000/4800 | Cost: 0.1397\n",
      "Epoch: 25/30 | Batch 3250/4800 | Cost: 0.2713\n",
      "Epoch: 25/30 | Batch 3500/4800 | Cost: 0.1521\n",
      "Epoch: 25/30 | Batch 3750/4800 | Cost: 0.1282\n",
      "Epoch: 25/30 | Batch 4000/4800 | Cost: 0.0755\n",
      "Epoch: 25/30 | Batch 4250/4800 | Cost: 0.1962\n",
      "Epoch: 25/30 | Batch 4500/4800 | Cost: 0.1888\n",
      "Epoch: 25/30 | Batch 4750/4800 | Cost: 0.0687\n",
      "Training: Correct[229992] | Wrong[10008] | Accuracy[95.83%] \n",
      "\n",
      "Epoch: 26/30 | Batch 0/4800 | Cost: 0.0831\n",
      "Epoch: 26/30 | Batch 250/4800 | Cost: 0.2131\n",
      "Epoch: 26/30 | Batch 500/4800 | Cost: 0.0828\n",
      "Epoch: 26/30 | Batch 750/4800 | Cost: 0.3704\n",
      "Epoch: 26/30 | Batch 1000/4800 | Cost: 0.1994\n",
      "Epoch: 26/30 | Batch 1250/4800 | Cost: 0.0324\n",
      "Epoch: 26/30 | Batch 1500/4800 | Cost: 0.0421\n",
      "Epoch: 26/30 | Batch 1750/4800 | Cost: 0.1866\n",
      "Epoch: 26/30 | Batch 2000/4800 | Cost: 0.0912\n",
      "Epoch: 26/30 | Batch 2250/4800 | Cost: 0.2150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/30 | Batch 2500/4800 | Cost: 0.0202\n",
      "Epoch: 26/30 | Batch 2750/4800 | Cost: 0.1054\n",
      "Epoch: 26/30 | Batch 3000/4800 | Cost: 0.1402\n",
      "Epoch: 26/30 | Batch 3250/4800 | Cost: 0.0940\n",
      "Epoch: 26/30 | Batch 3500/4800 | Cost: 0.2179\n",
      "Epoch: 26/30 | Batch 3750/4800 | Cost: 0.0442\n",
      "Epoch: 26/30 | Batch 4000/4800 | Cost: 0.1451\n",
      "Epoch: 26/30 | Batch 4250/4800 | Cost: 0.1144\n",
      "Epoch: 26/30 | Batch 4500/4800 | Cost: 0.0976\n",
      "Epoch: 26/30 | Batch 4750/4800 | Cost: 0.1035\n",
      "Training: Correct[230192] | Wrong[9808] | Accuracy[95.91%] \n",
      "\n",
      "Epoch: 27/30 | Batch 0/4800 | Cost: 0.0869\n",
      "Epoch: 27/30 | Batch 250/4800 | Cost: 0.1206\n",
      "Epoch: 27/30 | Batch 500/4800 | Cost: 0.0848\n",
      "Epoch: 27/30 | Batch 750/4800 | Cost: 0.1114\n",
      "Epoch: 27/30 | Batch 1000/4800 | Cost: 0.0841\n",
      "Epoch: 27/30 | Batch 1250/4800 | Cost: 0.1580\n",
      "Epoch: 27/30 | Batch 1500/4800 | Cost: 0.1143\n",
      "Epoch: 27/30 | Batch 1750/4800 | Cost: 0.1050\n",
      "Epoch: 27/30 | Batch 2000/4800 | Cost: 0.1117\n",
      "Epoch: 27/30 | Batch 2250/4800 | Cost: 0.1187\n",
      "Epoch: 27/30 | Batch 2500/4800 | Cost: 0.1349\n",
      "Epoch: 27/30 | Batch 2750/4800 | Cost: 0.0256\n",
      "Epoch: 27/30 | Batch 3000/4800 | Cost: 0.0466\n",
      "Epoch: 27/30 | Batch 3250/4800 | Cost: 0.1191\n",
      "Epoch: 27/30 | Batch 3500/4800 | Cost: 0.0985\n",
      "Epoch: 27/30 | Batch 3750/4800 | Cost: 0.2006\n",
      "Epoch: 27/30 | Batch 4000/4800 | Cost: 0.0403\n",
      "Epoch: 27/30 | Batch 4250/4800 | Cost: 0.3482\n",
      "Epoch: 27/30 | Batch 4500/4800 | Cost: 0.0391\n",
      "Epoch: 27/30 | Batch 4750/4800 | Cost: 0.1150\n",
      "Training: Correct[230488] | Wrong[9512] | Accuracy[96.04%] \n",
      "\n",
      "Epoch: 28/30 | Batch 0/4800 | Cost: 0.0703\n",
      "Epoch: 28/30 | Batch 250/4800 | Cost: 0.1232\n",
      "Epoch: 28/30 | Batch 500/4800 | Cost: 0.0578\n",
      "Epoch: 28/30 | Batch 750/4800 | Cost: 0.1066\n",
      "Epoch: 28/30 | Batch 1000/4800 | Cost: 0.0881\n",
      "Epoch: 28/30 | Batch 1250/4800 | Cost: 0.1771\n",
      "Epoch: 28/30 | Batch 1500/4800 | Cost: 0.0666\n",
      "Epoch: 28/30 | Batch 1750/4800 | Cost: 0.0734\n",
      "Epoch: 28/30 | Batch 2000/4800 | Cost: 0.0789\n",
      "Epoch: 28/30 | Batch 2250/4800 | Cost: 0.1219\n",
      "Epoch: 28/30 | Batch 2500/4800 | Cost: 0.1431\n",
      "Epoch: 28/30 | Batch 2750/4800 | Cost: 0.1802\n",
      "Epoch: 28/30 | Batch 3000/4800 | Cost: 0.1471\n",
      "Epoch: 28/30 | Batch 3250/4800 | Cost: 0.1403\n",
      "Epoch: 28/30 | Batch 3500/4800 | Cost: 0.0255\n",
      "Epoch: 28/30 | Batch 3750/4800 | Cost: 0.0732\n",
      "Epoch: 28/30 | Batch 4000/4800 | Cost: 0.1349\n",
      "Epoch: 28/30 | Batch 4250/4800 | Cost: 0.1883\n",
      "Epoch: 28/30 | Batch 4500/4800 | Cost: 0.3905\n",
      "Epoch: 28/30 | Batch 4750/4800 | Cost: 0.1403\n",
      "Training: Correct[230650] | Wrong[9350] | Accuracy[96.10%] \n",
      "\n",
      "Epoch: 29/30 | Batch 0/4800 | Cost: 0.1498\n",
      "Epoch: 29/30 | Batch 250/4800 | Cost: 0.0627\n",
      "Epoch: 29/30 | Batch 500/4800 | Cost: 0.2670\n",
      "Epoch: 29/30 | Batch 750/4800 | Cost: 0.1557\n",
      "Epoch: 29/30 | Batch 1000/4800 | Cost: 0.1702\n",
      "Epoch: 29/30 | Batch 1250/4800 | Cost: 0.1171\n",
      "Epoch: 29/30 | Batch 1500/4800 | Cost: 0.1165\n",
      "Epoch: 29/30 | Batch 1750/4800 | Cost: 0.1926\n",
      "Epoch: 29/30 | Batch 2000/4800 | Cost: 0.2501\n",
      "Epoch: 29/30 | Batch 2250/4800 | Cost: 0.0441\n",
      "Epoch: 29/30 | Batch 2500/4800 | Cost: 0.2095\n",
      "Epoch: 29/30 | Batch 2750/4800 | Cost: 0.0571\n",
      "Epoch: 29/30 | Batch 3000/4800 | Cost: 0.1628\n",
      "Epoch: 29/30 | Batch 3250/4800 | Cost: 0.1888\n",
      "Epoch: 29/30 | Batch 3500/4800 | Cost: 0.2843\n",
      "Epoch: 29/30 | Batch 3750/4800 | Cost: 0.1087\n",
      "Epoch: 29/30 | Batch 4000/4800 | Cost: 0.2038\n",
      "Epoch: 29/30 | Batch 4250/4800 | Cost: 0.1495\n",
      "Epoch: 29/30 | Batch 4500/4800 | Cost: 0.0702\n",
      "Epoch: 29/30 | Batch 4750/4800 | Cost: 0.0815\n",
      "Training: Correct[230044] | Wrong[9956] | Accuracy[95.85%] \n",
      "\n",
      "Epoch: 30/30 | Batch 0/4800 | Cost: 0.0350\n",
      "Epoch: 30/30 | Batch 250/4800 | Cost: 0.1646\n",
      "Epoch: 30/30 | Batch 500/4800 | Cost: 0.1382\n",
      "Epoch: 30/30 | Batch 750/4800 | Cost: 0.1016\n",
      "Epoch: 30/30 | Batch 1000/4800 | Cost: 0.1093\n",
      "Epoch: 30/30 | Batch 1250/4800 | Cost: 0.2099\n",
      "Epoch: 30/30 | Batch 1500/4800 | Cost: 0.1299\n",
      "Epoch: 30/30 | Batch 1750/4800 | Cost: 0.1319\n",
      "Epoch: 30/30 | Batch 2000/4800 | Cost: 0.2389\n",
      "Epoch: 30/30 | Batch 2250/4800 | Cost: 0.0692\n",
      "Epoch: 30/30 | Batch 2500/4800 | Cost: 0.1079\n",
      "Epoch: 30/30 | Batch 2750/4800 | Cost: 0.1094\n",
      "Epoch: 30/30 | Batch 3000/4800 | Cost: 0.0201\n",
      "Epoch: 30/30 | Batch 3250/4800 | Cost: 0.1879\n",
      "Epoch: 30/30 | Batch 3500/4800 | Cost: 0.0942\n",
      "Epoch: 30/30 | Batch 3750/4800 | Cost: 0.1111\n",
      "Epoch: 30/30 | Batch 4000/4800 | Cost: 0.1544\n",
      "Epoch: 30/30 | Batch 4250/4800 | Cost: 0.1579\n",
      "Epoch: 30/30 | Batch 4500/4800 | Cost: 0.1899\n",
      "Epoch: 30/30 | Batch 4750/4800 | Cost: 0.1825\n",
      "Training: Correct[230900] | Wrong[9100] | Accuracy[96.21%] \n",
      "\n",
      "Training time: 3173.49 seconds on cuda\n"
     ]
    }
   ],
   "source": [
    "fit(model_class, train_loader, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d36f5c",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- HOW TO MERGE THESE TWO TRAINED NETWORKS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7256aaa3",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f533e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_index, (features, image_id) in enumerate(test_loader):\n",
    "        features = features.to(device)\n",
    "\n",
    "        logits = net(features)\n",
    "        _, predictions = torch.max(logits, dim=1) # single class with highest probability. simply retain indices\n",
    "            \n",
    "        for i, features in enumerate(features): # now iterate over each element of the current batch\n",
    "            results.append(\n",
    "                [image_id[i].detach().numpy(), predictions[i].cpu().numpy()]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7f1566a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240001</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240003</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240004</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id classification\n",
       "0  240000              6\n",
       "1  240001              9\n",
       "2  240002              0\n",
       "3  240003              8\n",
       "4  240004              2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results, columns =['id', 'classification'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0da91b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"submission.csv\", index=False, sep=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
