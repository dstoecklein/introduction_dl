{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04d7a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488b0d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6cc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../datasets/MixedMNIST/'\n",
    "images_dir = '../datasets/MixedMNIST/images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce81c8b",
   "metadata": {},
   "source": [
    "# Mnist Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15753cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = ImageFolder(\n",
    "    images_dir + 'train', \n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor()\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860658b8",
   "metadata": {},
   "source": [
    "# Mnist Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Test(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.image_id = self.annotations.id\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 1]) # 'image' column\n",
    "        image = Image.open(img_path)\n",
    "        image_id = self.image_id[index]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee2711",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = MNIST_Test(\n",
    "    csv_file = root_dir + 'test.csv', \n",
    "    root_dir = images_dir + 'test', \n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Grayscale(num_output_channels = 1),\n",
    "            transforms.ToTensor()\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a1fc7b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5066afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "                \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe8c93",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b826e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_accuracy(model, data_loader):\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    num_examples = 0\n",
    "    \n",
    "    # turn on eval mode if model Inherits from nn.Module\n",
    "    if isinstance(model, nn.Module):\n",
    "        model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_index, (features, labels) in enumerate(data_loader):\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(features)\n",
    "            _, predictions = torch.max(logits, dim=1) # single class with highest probability. simply retain indices\n",
    "            \n",
    "            num_examples += labels.size(0)\n",
    "\n",
    "            correct += (predictions == labels).sum().float()\n",
    "            wrong += (predictions != labels).sum().float()\n",
    "            \n",
    "        accuracy = correct / num_examples * 100      \n",
    "        \n",
    "    return correct, wrong, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb32e29",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6fae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader, epochs, learning_rate, loss_func=nn.CrossEntropyLoss(), opt_func=torch.optim.SGD):\n",
    "    \n",
    "    optimizer = opt_func(model.parameters(), learning_rate) # objective function\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    start = time.time() # measure time\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model = model.train()\n",
    "              \n",
    "        for batch_index, (features, labels) in enumerate(train_loader):\n",
    "            \n",
    "            # gpu usage if possible\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 1. forward\n",
    "            logits = model(features)\n",
    "\n",
    "            # 2. compute objective function (softmax, cross entropy)\n",
    "            cost = loss_func(logits, labels)\n",
    "            \n",
    "            # 3. cleaning gradients\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            # 4. accumulate partial derivatives\n",
    "            cost.backward() \n",
    "\n",
    "            # 5. step in the opposite direction of the gradient\n",
    "            optimizer.step() \n",
    "            \n",
    "            if not batch_index % 250:\n",
    "                print ('Epoch: {}/{} | Batch {}/{} | Cost: {:.4f}'.format(\n",
    "                    epoch+1,\n",
    "                    epochs,\n",
    "                    batch_index,\n",
    "                    len(train_loader),\n",
    "                    cost\n",
    "                ))\n",
    "        \n",
    "        correct, wrong, accuracy = comp_accuracy(model, train_loader)\n",
    "        print ('Training: Correct[{:.0f}] | Wrong[{:.0f}] | Accuracy[{:.2f}%]'.format(\n",
    "            correct,\n",
    "            wrong,\n",
    "            accuracy\n",
    "        ), '\\n')\n",
    "         \n",
    "    end = time.time()\n",
    "    print('Training time: {:.2f} seconds on {}'.format(\n",
    "        end - start, \n",
    "        device\n",
    "    ))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d97d915",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a044c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 60\n",
    "learning_rate = 0.08\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e928a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = Model()\n",
    "fit(model_test, train_loader, epochs, learning_rate, loss_func=nn.NLLLoss(), opt_func=torch.optim.Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60b8df0",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f533e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_index, (features, image_id) in enumerate(test_loader):\n",
    "        features = features.to(device)\n",
    "\n",
    "        logits = net(features)\n",
    "        _, predictions = torch.max(logits, dim=1) # single class with highest probability. simply retain indices\n",
    "            \n",
    "        for i, features in enumerate(features): # now iterate over each element of the current batch\n",
    "            results.append(\n",
    "                [image_id[i].detach().numpy(), predictions[i].cpu().numpy()]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f1566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns =['id', 'classification'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da91b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"submission.csv\", index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08562bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
