{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04d7a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "488b0d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec6cc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../datasets/MixedMNIST/'\n",
    "images_dir = '../datasets/MixedMNIST/images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce81c8b",
   "metadata": {},
   "source": [
    "# Mnist Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15753cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = ImageFolder(\n",
    "    images_dir + 'train', \n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor()\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860658b8",
   "metadata": {},
   "source": [
    "# Mnist Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb6c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Test(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.image_id = self.annotations.id\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 1]) # 'image' column\n",
    "        image = Image.open(img_path)\n",
    "        image_id = self.image_id[index]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7ee2711",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = MNIST_Test(\n",
    "    csv_file = root_dir + 'test.csv', \n",
    "    root_dir = images_dir + 'test', \n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Grayscale(num_output_channels = 1),\n",
    "            transforms.ToTensor()\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a1fc7b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5066afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n",
    "    ):\n",
    "        super(block, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            intermediate_channels,\n",
    "            intermediate_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            intermediate_channels,\n",
    "            intermediate_channels * self.expansion,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, image_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Essentially the entire ResNet architecture are in these 4 lines below\n",
    "        self.layer1 = self._make_layer(\n",
    "            block, layers[0], intermediate_channels=64, stride=1\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block, layers[1], intermediate_channels=128, stride=2\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block, layers[2], intermediate_channels=256, stride=2\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block, layers[3], intermediate_channels=512, stride=2\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
    "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
    "        # to the layer that's ahead\n",
    "        if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
    "            identity_downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.in_channels,\n",
    "                    intermediate_channels * 4,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(intermediate_channels * 4),\n",
    "            )\n",
    "\n",
    "        layers.append(\n",
    "            block(self.in_channels, intermediate_channels, identity_downsample, stride)\n",
    "        )\n",
    "\n",
    "        # The expansion size is always 4 for ResNet 50,101,152\n",
    "        self.in_channels = intermediate_channels * 4\n",
    "\n",
    "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
    "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
    "        # and also same amount of channels.\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, intermediate_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28c5ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(img_channels=1, num_classes=10):\n",
    "    return ResNet(block, [3, 4, 6, 3], img_channels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe8c93",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b826e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_accuracy(model, data_loader):\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    num_examples = 0\n",
    "    \n",
    "    # turn on eval mode if model Inherits from nn.Module\n",
    "    if isinstance(model, nn.Module):\n",
    "        model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_index, (features, labels) in enumerate(data_loader):\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(features)\n",
    "            _, predictions = torch.max(logits, dim=1) # single class with highest probability. simply retain indices\n",
    "            \n",
    "            num_examples += labels.size(0)\n",
    "\n",
    "            correct += (predictions == labels).sum().float()\n",
    "            wrong += (predictions != labels).sum().float()\n",
    "            \n",
    "        accuracy = correct / num_examples * 100      \n",
    "        \n",
    "    return correct, wrong, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb32e29",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be6fae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader, epochs, learning_rate, loss_func=nn.CrossEntropyLoss(), opt_func=torch.optim.SGD):\n",
    "    \n",
    "    optimizer = opt_func(model.parameters(), learning_rate) # objective function\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    start = time.time() # measure time\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model = model.train()\n",
    "              \n",
    "        for batch_index, (features, labels) in enumerate(train_loader):\n",
    "            \n",
    "            # gpu usage if possible\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 1. forward\n",
    "            logits = model(features)\n",
    "\n",
    "            # 2. compute objective function (softmax, cross entropy)\n",
    "            cost = loss_func(logits, labels)\n",
    "            \n",
    "            # 3. cleaning gradients\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            # 4. accumulate partial derivatives\n",
    "            cost.backward() \n",
    "\n",
    "            # 5. step in the opposite direction of the gradient\n",
    "            optimizer.step() \n",
    "            \n",
    "            if not batch_index % 250:\n",
    "                print ('Epoch: {}/{} | Batch {}/{} | Cost: {:.4f}'.format(\n",
    "                    epoch+1,\n",
    "                    epochs,\n",
    "                    batch_index,\n",
    "                    len(train_loader),\n",
    "                    cost\n",
    "                ))\n",
    "        \n",
    "        correct, wrong, accuracy = comp_accuracy(model, train_loader)\n",
    "        print ('Training: Correct[{:.0f}] | Wrong[{:.0f}] | Accuracy[{:.2f}%]'.format(\n",
    "            correct,\n",
    "            wrong,\n",
    "            accuracy\n",
    "        ), '\\n')\n",
    "         \n",
    "    end = time.time()\n",
    "    print('Training time: {:.2f} seconds on {}'.format(\n",
    "        end - start, \n",
    "        device\n",
    "    ))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d97d915",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a044c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 60\n",
    "learning_rate = 0.08\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e928a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/60 | Batch 0/2400 | Cost: 2.5593\n",
      "Epoch: 1/60 | Batch 250/2400 | Cost: 1.7124\n",
      "Epoch: 1/60 | Batch 500/2400 | Cost: 1.9342\n",
      "Epoch: 1/60 | Batch 750/2400 | Cost: 1.9231\n",
      "Epoch: 1/60 | Batch 1000/2400 | Cost: 0.6802\n",
      "Epoch: 1/60 | Batch 1250/2400 | Cost: 0.3942\n",
      "Epoch: 1/60 | Batch 1500/2400 | Cost: 0.6664\n",
      "Epoch: 1/60 | Batch 1750/2400 | Cost: 0.4926\n",
      "Epoch: 1/60 | Batch 2000/2400 | Cost: 0.2220\n",
      "Epoch: 1/60 | Batch 2250/2400 | Cost: 0.5275\n",
      "Training: Correct[212259] | Wrong[27741] | Accuracy[88.44%] \n",
      "\n",
      "Epoch: 2/60 | Batch 0/2400 | Cost: 0.4333\n",
      "Epoch: 2/60 | Batch 250/2400 | Cost: 0.2671\n",
      "Epoch: 2/60 | Batch 500/2400 | Cost: 0.2100\n",
      "Epoch: 2/60 | Batch 750/2400 | Cost: 0.2532\n",
      "Epoch: 2/60 | Batch 1000/2400 | Cost: 0.2757\n",
      "Epoch: 2/60 | Batch 1250/2400 | Cost: 0.3298\n",
      "Epoch: 2/60 | Batch 1500/2400 | Cost: 0.4880\n",
      "Epoch: 2/60 | Batch 1750/2400 | Cost: 0.1902\n",
      "Epoch: 2/60 | Batch 2000/2400 | Cost: 0.3657\n",
      "Epoch: 2/60 | Batch 2250/2400 | Cost: 0.2855\n",
      "Training: Correct[219501] | Wrong[20499] | Accuracy[91.46%] \n",
      "\n",
      "Epoch: 3/60 | Batch 0/2400 | Cost: 0.2662\n",
      "Epoch: 3/60 | Batch 250/2400 | Cost: 0.2169\n",
      "Epoch: 3/60 | Batch 500/2400 | Cost: 0.2069\n",
      "Epoch: 3/60 | Batch 750/2400 | Cost: 0.2738\n",
      "Epoch: 3/60 | Batch 1000/2400 | Cost: 0.2738\n",
      "Epoch: 3/60 | Batch 1250/2400 | Cost: 0.1401\n",
      "Epoch: 3/60 | Batch 1500/2400 | Cost: 0.2419\n",
      "Epoch: 3/60 | Batch 1750/2400 | Cost: 0.2007\n",
      "Epoch: 3/60 | Batch 2000/2400 | Cost: 0.2708\n",
      "Epoch: 3/60 | Batch 2250/2400 | Cost: 0.1830\n",
      "Training: Correct[222250] | Wrong[17750] | Accuracy[92.60%] \n",
      "\n",
      "Epoch: 4/60 | Batch 0/2400 | Cost: 0.1828\n",
      "Epoch: 4/60 | Batch 250/2400 | Cost: 0.1683\n",
      "Epoch: 4/60 | Batch 500/2400 | Cost: 0.1604\n",
      "Epoch: 4/60 | Batch 750/2400 | Cost: 0.2326\n",
      "Epoch: 4/60 | Batch 1000/2400 | Cost: 0.2057\n",
      "Epoch: 4/60 | Batch 1250/2400 | Cost: 0.1530\n",
      "Epoch: 4/60 | Batch 1500/2400 | Cost: 0.2111\n",
      "Epoch: 4/60 | Batch 1750/2400 | Cost: 0.2035\n",
      "Epoch: 4/60 | Batch 2000/2400 | Cost: 0.1345\n",
      "Epoch: 4/60 | Batch 2250/2400 | Cost: 0.2058\n",
      "Training: Correct[223664] | Wrong[16336] | Accuracy[93.19%] \n",
      "\n",
      "Epoch: 5/60 | Batch 0/2400 | Cost: 0.2562\n",
      "Epoch: 5/60 | Batch 250/2400 | Cost: 0.1531\n",
      "Epoch: 5/60 | Batch 500/2400 | Cost: 0.2992\n",
      "Epoch: 5/60 | Batch 750/2400 | Cost: 0.1812\n",
      "Epoch: 5/60 | Batch 1000/2400 | Cost: 0.2030\n",
      "Epoch: 5/60 | Batch 1250/2400 | Cost: 0.2457\n",
      "Epoch: 5/60 | Batch 1500/2400 | Cost: 0.2722\n",
      "Epoch: 5/60 | Batch 1750/2400 | Cost: 0.1629\n",
      "Epoch: 5/60 | Batch 2000/2400 | Cost: 0.2721\n",
      "Epoch: 5/60 | Batch 2250/2400 | Cost: 0.1821\n",
      "Training: Correct[226518] | Wrong[13482] | Accuracy[94.38%] \n",
      "\n",
      "Epoch: 6/60 | Batch 0/2400 | Cost: 0.2417\n",
      "Epoch: 6/60 | Batch 250/2400 | Cost: 0.1309\n",
      "Epoch: 6/60 | Batch 500/2400 | Cost: 0.1908\n",
      "Epoch: 6/60 | Batch 750/2400 | Cost: 0.2702\n",
      "Epoch: 6/60 | Batch 1000/2400 | Cost: 0.0739\n",
      "Epoch: 6/60 | Batch 1250/2400 | Cost: 0.1864\n",
      "Epoch: 6/60 | Batch 1500/2400 | Cost: 0.2443\n",
      "Epoch: 6/60 | Batch 1750/2400 | Cost: 0.1609\n",
      "Epoch: 6/60 | Batch 2000/2400 | Cost: 0.1248\n",
      "Epoch: 6/60 | Batch 2250/2400 | Cost: 0.1685\n",
      "Training: Correct[227230] | Wrong[12770] | Accuracy[94.68%] \n",
      "\n",
      "Epoch: 7/60 | Batch 0/2400 | Cost: 0.1597\n",
      "Epoch: 7/60 | Batch 250/2400 | Cost: 0.0994\n",
      "Epoch: 7/60 | Batch 500/2400 | Cost: 0.1750\n",
      "Epoch: 7/60 | Batch 750/2400 | Cost: 0.2775\n",
      "Epoch: 7/60 | Batch 1000/2400 | Cost: 0.2317\n",
      "Epoch: 7/60 | Batch 1250/2400 | Cost: 0.1138\n",
      "Epoch: 7/60 | Batch 1500/2400 | Cost: 0.1738\n",
      "Epoch: 7/60 | Batch 1750/2400 | Cost: 0.0460\n",
      "Epoch: 7/60 | Batch 2000/2400 | Cost: 0.1012\n",
      "Epoch: 7/60 | Batch 2250/2400 | Cost: 0.2119\n",
      "Training: Correct[227818] | Wrong[12182] | Accuracy[94.92%] \n",
      "\n",
      "Epoch: 8/60 | Batch 0/2400 | Cost: 0.1557\n",
      "Epoch: 8/60 | Batch 250/2400 | Cost: 0.1382\n",
      "Epoch: 8/60 | Batch 500/2400 | Cost: 0.2068\n",
      "Epoch: 8/60 | Batch 750/2400 | Cost: 0.2938\n",
      "Epoch: 8/60 | Batch 1000/2400 | Cost: 0.2014\n",
      "Epoch: 8/60 | Batch 1250/2400 | Cost: 0.1735\n",
      "Epoch: 8/60 | Batch 1500/2400 | Cost: 0.1463\n",
      "Epoch: 8/60 | Batch 1750/2400 | Cost: 0.1735\n",
      "Epoch: 8/60 | Batch 2000/2400 | Cost: 0.0760\n",
      "Epoch: 8/60 | Batch 2250/2400 | Cost: 0.1320\n",
      "Training: Correct[229255] | Wrong[10745] | Accuracy[95.52%] \n",
      "\n",
      "Epoch: 9/60 | Batch 0/2400 | Cost: 0.1100\n",
      "Epoch: 9/60 | Batch 250/2400 | Cost: 0.1549\n",
      "Epoch: 9/60 | Batch 500/2400 | Cost: 0.1591\n",
      "Epoch: 9/60 | Batch 750/2400 | Cost: 0.0964\n",
      "Epoch: 9/60 | Batch 1000/2400 | Cost: 0.0834\n",
      "Epoch: 9/60 | Batch 1250/2400 | Cost: 0.1502\n",
      "Epoch: 9/60 | Batch 1500/2400 | Cost: 0.1698\n",
      "Epoch: 9/60 | Batch 1750/2400 | Cost: 0.0444\n",
      "Epoch: 9/60 | Batch 2000/2400 | Cost: 0.1359\n",
      "Epoch: 9/60 | Batch 2250/2400 | Cost: 0.2835\n",
      "Training: Correct[229740] | Wrong[10260] | Accuracy[95.72%] \n",
      "\n",
      "Epoch: 10/60 | Batch 0/2400 | Cost: 0.1062\n",
      "Epoch: 10/60 | Batch 250/2400 | Cost: 0.0421\n",
      "Epoch: 10/60 | Batch 500/2400 | Cost: 0.0753\n",
      "Epoch: 10/60 | Batch 750/2400 | Cost: 0.1696\n",
      "Epoch: 10/60 | Batch 1000/2400 | Cost: 0.0980\n",
      "Epoch: 10/60 | Batch 1250/2400 | Cost: 0.0901\n",
      "Epoch: 10/60 | Batch 1500/2400 | Cost: 0.0684\n",
      "Epoch: 10/60 | Batch 1750/2400 | Cost: 0.0882\n",
      "Epoch: 10/60 | Batch 2000/2400 | Cost: 0.1321\n",
      "Epoch: 10/60 | Batch 2250/2400 | Cost: 0.1792\n",
      "Training: Correct[229909] | Wrong[10091] | Accuracy[95.80%] \n",
      "\n",
      "Epoch: 11/60 | Batch 0/2400 | Cost: 0.0760\n",
      "Epoch: 11/60 | Batch 250/2400 | Cost: 0.1146\n",
      "Epoch: 11/60 | Batch 500/2400 | Cost: 0.0868\n",
      "Epoch: 11/60 | Batch 750/2400 | Cost: 0.0755\n",
      "Epoch: 11/60 | Batch 1000/2400 | Cost: 0.1416\n",
      "Epoch: 11/60 | Batch 1250/2400 | Cost: 0.0849\n",
      "Epoch: 11/60 | Batch 1500/2400 | Cost: 0.0929\n",
      "Epoch: 11/60 | Batch 1750/2400 | Cost: 0.1169\n",
      "Epoch: 11/60 | Batch 2000/2400 | Cost: 0.1555\n",
      "Epoch: 11/60 | Batch 2250/2400 | Cost: 0.0490\n",
      "Training: Correct[232294] | Wrong[7706] | Accuracy[96.79%] \n",
      "\n",
      "Epoch: 12/60 | Batch 0/2400 | Cost: 0.1173\n",
      "Epoch: 12/60 | Batch 250/2400 | Cost: 0.1009\n",
      "Epoch: 12/60 | Batch 500/2400 | Cost: 0.1152\n",
      "Epoch: 12/60 | Batch 750/2400 | Cost: 0.1662\n",
      "Epoch: 12/60 | Batch 1000/2400 | Cost: 0.1225\n"
     ]
    }
   ],
   "source": [
    "net = ResNet50()\n",
    "fit(net, train_loader, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60b8df0",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f533e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_index, (features, image_id) in enumerate(test_loader):\n",
    "        features = features.to(device)\n",
    "\n",
    "        logits = net(features)\n",
    "        _, predictions = torch.max(logits, dim=1) # single class with highest probability. simply retain indices\n",
    "            \n",
    "        for i, features in enumerate(features): # now iterate over each element of the current batch\n",
    "            results.append(\n",
    "                [image_id[i].detach().numpy(), predictions[i].cpu().numpy()]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f1566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns =['id', 'classification'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da91b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"submission.csv\", index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08562bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
