{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09213e4a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear algebra in PyTorch\n",
    "\n",
    "* objects\n",
    "* operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab098154",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scalars\n",
    "\n",
    "**tensors** with 1 element, they have no shape (size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed7c4774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.5800), tensor(1276))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x, y = torch.tensor(2.58), torch.tensor(1276)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9603898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([]), 1, torch.float32, torch.int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x.numel(), x.dtype, y.dtype\n",
    "# it has no dimension, so empty shape\n",
    "# numel = number of elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d14a29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vectors\n",
    "\n",
    "1-dim `torch.tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baaa339f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e007c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5]), 5, 5, torch.int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x.numel(), len(x), x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b43bea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Matrices\n",
    "\n",
    "2-dim `torch.tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efdf06da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(12).view(3, 4)\n",
    "# give me 12 integers and view at as a 3x4 matrix\n",
    "# 3 rows, 4 columns\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f84edd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), 12, 3, torch.int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.numel(), len(A), A.dtype\n",
    "# len: it doesnt know what it means for a matrix, so it takes just the first dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a9407f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tensors\n",
    "\n",
    "higher-dim `torch.tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "488bfcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = torch.arange(24).view(-1, 3, 4)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "164c3ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4]), 24, 2, torch.int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape, Z.numel(), len(Z), Z.dtype\n",
    "# 2 length, 3 rows, 4 columns, 12 * 2 = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adf9137",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic operations\n",
    "\n",
    "### Transpose - flip axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d90c4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]]),\n",
       " tensor([[ 0,  4,  8],\n",
       "         [ 1,  5,  9],\n",
       "         [ 2,  6, 10],\n",
       "         [ 3,  7, 11]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3256bc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), torch.Size([4, 3]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cedb7a",
   "metadata": {
    "origin_pos": 52,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reduction operation\n",
    "There are many, check documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a84a9d60",
   "metadata": {
    "origin_pos": 54,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor(6.))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4, dtype=torch.float32)\n",
    "x, x.sum()\n",
    "# 1+2+3 = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20a32cb",
   "metadata": {
    "origin_pos": 56,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reduction axis specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94de7293",
   "metadata": {
    "origin_pos": 58,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), tensor(66))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce all elements\n",
    "A.shape, A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edf39f0b",
   "metadata": {
    "origin_pos": 62,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([12, 15, 18, 21]), torch.Size([4]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce along axis=0 (rows)\n",
    "A_sum_axis0 = A.sum(axis=0)\n",
    "A_sum_axis0, A_sum_axis0.shape\n",
    "\n",
    "# sum across rows, axis=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71fa74dc",
   "metadata": {
    "origin_pos": 66,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6, 22, 38]), torch.Size([3]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce along axis=1 (columns)\n",
    "A_sum_axis1 = A.sum(axis=1)\n",
    "A_sum_axis1, A_sum_axis1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c869664f",
   "metadata": {
    "origin_pos": 70,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(66), tensor(66))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce along all axis\n",
    "A.sum(axis=[0, 1]), A.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c15d44a",
   "metadata": {
    "origin_pos": 80,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Non-Reduction Sum\n",
    "\n",
    "Reduce elements but keep number of axes unchanged `keepdims=True`(useful for broadcasting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d96bd9c7",
   "metadata": {
    "origin_pos": 82,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6],\n",
       "         [22],\n",
       "         [38]]),\n",
       " torch.Size([3, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=1, keepdims=True), A.sum(axis=1, keepdims=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7902705a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6, 22, 38]), torch.Size([3]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=1), A.sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026e3d4f",
   "metadata": {
    "origin_pos": 92,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dot Products\n",
    "\n",
    "two vectors $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^d$\n",
    "\n",
    "**dot product**: $\\quad \\mathbf{x}^\\top \\mathbf{y} = \\langle \\mathbf{x}, \\mathbf{y}  \\rangle = \\sum_{i=1}^{d} x_i y_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7997c1c",
   "metadata": {
    "origin_pos": 94,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4.)\n",
    "y = torch.ones(4, dtype=torch.float32)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "729f374b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]),\n",
       " tensor([1., 1., 1., 1.]),\n",
       " tensor(6.),\n",
       " tensor(6.),\n",
       " tensor(6.))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y, torch.dot(x, y), (x*y).sum(), x.dot(y)\n",
    "# last 3 same operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51f5af0",
   "metadata": {
    "origin_pos": 100,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matrix-Vector Products\n",
    "\n",
    "matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ and vector $\\mathbf{x} \\in \\mathbb{R}^n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "101a54e9",
   "metadata": {
    "origin_pos": 105,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5195, -0.0674, -1.0511, -1.1626],\n",
       "        [-0.6995, -2.1672,  0.5128,  0.7514],\n",
       "        [ 0.2593, -0.8123,  0.5161,  2.2874]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn(3,4)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac3bf6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]),\n",
       " torch.Size([4]),\n",
       " tensor([-5.6576,  1.1126,  7.0822]),\n",
       " tensor([-5.6576,  1.1126,  7.0822]),\n",
       " tensor(7.0822))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, x.shape, torch.mv(A, x), A.mv(x), A[2,:].dot(x) #2. rows mult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6415f0",
   "metadata": {
    "origin_pos": 107,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matrix-Matrix Multiplication\n",
    "\n",
    "$\\mathbf{A} \\in \\mathbb{R}^{n \\times k}$ and $\\mathbf{B} \\in \\mathbb{R}^{k \\times m}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1682498b",
   "metadata": {
    "origin_pos": 109,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.1690,  0.4869],\n",
       "         [ 2.0671,  0.5512],\n",
       "         [ 0.1609, -2.9475]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, k, m = 3, 4, 2\n",
    "A, B = torch.randn(n,k), torch.randn(k, m)\n",
    "C = torch.mm(A, B)\n",
    "C, C.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a99b7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`torch.matmul` generic function for all the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e001c626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6.),\n",
       " tensor([-5.6576,  1.1126,  7.0822]),\n",
       " tensor([[-3.8647, -1.4330],\n",
       "         [ 3.1556,  0.4487],\n",
       "         [ 4.4584,  0.0476]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x, y), torch.matmul(A, x), torch.matmul(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d7781d",
   "metadata": {
    "origin_pos": 111,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Norms\n",
    "$L_2$ norm $\\qquad \\|\\mathbf{x}\\| = \\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_i x_i^2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e741a89",
   "metadata": {
    "origin_pos": 113,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor(3.7417), tensor(1.))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, torch.norm(x), torch.norm(x[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d864dc33",
   "metadata": {
    "origin_pos": 115,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other norms\n",
    "\n",
    "$L_1$ norm $\\qquad \\|\\mathbf{x}\\|_1 = \\sum_{i=1}^n \\left|x_i \\right|$\n",
    "\n",
    "\n",
    "$L_p$ norm $\\qquad \\|\\mathbf{x}\\|_p = \\left(\\sum_{i=1}^n \\left|x_i \\right|^p \\right)^{1/p}$\n",
    "\n",
    "Frobenious norm $\\qquad \\|\\mathbf{X}\\|_F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n x_{ij}^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9d3d164",
   "metadata": {
    "origin_pos": 117,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor(6.), tensor(6.), tensor(3.3019))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, torch.abs(x).sum(), torch.norm(x, 1), torch.norm(x, 3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "586b9851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.5195, -0.0674, -1.0511, -1.1626],\n",
       "         [-0.6995, -2.1672,  0.5128,  0.7514],\n",
       "         [ 0.2593, -0.8123,  0.5161,  2.2874]]),\n",
       " tensor(3.8692),\n",
       " tensor(3.8692),\n",
       " tensor(3.8692))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, torch.norm(A), torch.norm(A, 'fro'), torch.norm(A.flatten(), 2)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "f2575392019334285e0602a4035eec46b9260ee4c95297ea34ade6e3c8b8fcaf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
